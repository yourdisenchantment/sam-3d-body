import sys
import os
import gradio as gr
import torch
import cv2
import json
import numpy as np
import trimesh
import trimesh.creation
import trimesh.util
import uuid
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–æ–≤
sys.path.append(os.getcwd())

from sam_3d_body import load_sam_3d_body, SAM3DBodyEstimator

# –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä (—Ç–∞–∫ –∫–∞–∫ –º—ã —Å—Ç–∞–≤–∏–ª–∏ detectron2)
try:
    from tools.build_detector import HumanDetector

    HAS_DETECTOR = True
except ImportError:
    print("‚ö†Ô∏è Detectron2 –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ HumanDetector –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
    HAS_DETECTOR = False

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
CHECKPOINT_DIR = Path("checkpoints/sam-3d-body-dinov3")

# –ò–µ—Ä–∞—Ä—Ö–∏—è —Ä–æ–¥–∏—Ç–µ–ª–µ–π SMPL (–¥–ª—è —Ä–∏—Å–æ–≤–∞–Ω–∏—è –∫–æ—Å—Ç–µ–π)
SMPL_PARENTS = [
    -1,
    0,
    0,
    0,
    1,
    2,
    3,
    4,
    5,
    6,
    7,
    8,
    9,
    9,
    9,
    12,
    13,
    14,
    16,
    17,
    18,
    19,
    20,
    21,
]

# –¶–≤–µ—Ç–∞ (R, G, B, A)
COLOR_SKELETON = [255, 50, 50, 255]  # –Ø—Ä–∫–æ-–∫—Ä–∞—Å–Ω—ã–π, –Ω–µ–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π
COLOR_SKIN = [200, 200, 200, 100]  # –°–µ—Ä—ã–π, –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π


def find_paths():
    if not CHECKPOINT_DIR.exists():
        raise FileNotFoundError(f"–ù–µ—Ç –ø–∞–ø–∫–∏ {CHECKPOINT_DIR}")

    # –ò—â–µ–º –≤–µ—Å–∞
    files = (
        list(CHECKPOINT_DIR.glob("*.ckpt"))
        + list(CHECKPOINT_DIR.glob("*.pth"))
        + list(CHECKPOINT_DIR.glob("*.safetensors"))
    )
    files.sort(key=lambda x: x.stat().st_size, reverse=True)
    if not files:
        raise FileNotFoundError("–ù–µ—Ç –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏!")

    # –ò—â–µ–º Asset
    mhr = CHECKPOINT_DIR / "assets" / "mhr_model.pt"
    if not mhr.exists():
        mhr = CHECKPOINT_DIR / "mhr_model.pt"

    return str(files[0]), str(mhr)


# --- –ó–ê–ì–†–£–ó–ö–ê ---
print(f"‚è≥ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –Ω–∞ {DEVICE}...")
try:
    c_path, m_path = find_paths()
    print(f"üìÇ Load: {Path(c_path).name}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    model, cfg = load_sam_3d_body(c_path, device=DEVICE, mhr_path=m_path)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä
    det = None
    if HAS_DETECTOR:
        print("üïµÔ∏è –ó–∞–ø—É—Å–∫–∞–µ–º HumanDetector (ViTDet)...")
        try:
            det = HumanDetector(name="vitdet", device=DEVICE)
            print("‚úÖ –î–µ—Ç–µ–∫—Ç–æ—Ä –≥–æ—Ç–æ–≤!")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: {e}")

    estimator = SAM3DBodyEstimator(
        sam_3d_body_model=model, model_cfg=cfg, human_detector=det
    )
    print("üöÄ –°–∏—Å—Ç–µ–º–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≥–æ—Ç–æ–≤–∞!")

except Exception as e:
    print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
    exit(1)


# --- –£–¢–ò–õ–ò–¢–´ ---
def serialize(obj):
    if isinstance(obj, torch.Tensor):
        return obj.detach().cpu().numpy().tolist()
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    return str(obj)


def create_skeleton_mesh(joints):
    """–°—Ç—Ä–æ–∏—Ç –≥–µ–æ–º–µ—Ç—Ä–∏—é —Å–∫–µ–ª–µ—Ç–∞ (—Å—Ñ–µ—Ä—ã + —Ü–∏–ª–∏–Ω–¥—Ä—ã)"""
    parts = []
    limit = min(len(joints), len(SMPL_PARENTS))

    for i in range(limit):
        loc = joints[i]

        # –°—É—Å—Ç–∞–≤ (–°—Ñ–µ—Ä–∞)
        sphere = trimesh.creation.icosphere(radius=0.035, subdivisions=1)
        sphere.apply_translation(loc)
        parts.append(sphere)

        # –ö–æ—Å—Ç—å (–¶–∏–ª–∏–Ω–¥—Ä)
        parent_idx = SMPL_PARENTS[i]
        if parent_idx != -1 and parent_idx < len(joints):
            bone = trimesh.creation.cylinder(
                radius=0.02, segment=[loc, joints[parent_idx]]
            )
            parts.append(bone)

    if not parts:
        return None

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ –æ–¥–∏–Ω –º–µ—à –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    skeleton = trimesh.util.concatenate(parts)
    skeleton.visual.face_colors = COLOR_SKELETON
    return skeleton


def run_inference(input_image):
    if input_image is None:
        return None, None

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è, —á—Ç–æ–±—ã –±—Ä–∞—É–∑–µ—Ä –Ω–µ –∫—ç—à–∏—Ä–æ–≤–∞–ª —Å—Ç–∞—Ä—É—é –º–æ–¥–µ–ª—å
    uid = uuid.uuid4().hex[:6]
    temp_img = f"temp_{uid}.jpg"
    glb_out = f"result_{uid}.glb"
    json_out = f"skeleton_{uid}.json"

    print(f"\nüì∏ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ {uid}...")

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ BGR
    cv2.imwrite(temp_img, cv2.cvtColor(input_image, cv2.COLOR_RGB2BGR))

    outputs = []
    try:
        # –ï—Å–ª–∏ –µ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä, bbox_thr –æ—Ç—Å–µ—á–µ—Ç –º—É—Å–æ—Ä.
        # –ï—Å–ª–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –Ω–µ—Ç, –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –≤–∑—è—Ç—å –≤—Å—é –∫–∞—Ä—Ç–∏–Ω–∫—É.
        outputs = estimator.process_one_image(temp_img, bbox_thr=0.5)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞: {e}")

    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º—è–Ω–∫—É
    if os.path.exists(temp_img):
        os.remove(temp_img)

    if not outputs:
        print("‚ö†Ô∏è –õ—é–¥–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return None, None

    print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ª—é–¥–µ–π: {len(outputs)}")
    person = outputs[0]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤–æ–≥–æ

    # --- 1. JSON Export ---
    json_data = {"joints_3d": []}
    joints_np = None

    if "pred_joints" in person:
        json_data["joints_3d"] = serialize(person["pred_joints"])
        joints_np = person["pred_joints"].detach().cpu().numpy()
    elif "joints" in person:
        json_data["joints_3d"] = serialize(person["joints"])
        joints_np = person["joints"].detach().cpu().numpy()

    with open(json_out, "w") as f:
        json.dump(json_data, f, indent=2)

    # --- 2. 3D GLB Export ---
    v = person.get("pred_vertices")
    f = estimator.faces

    scene_meshes = []

    # –¢–µ–ª–æ
    if v is not None and f is not None:
        if isinstance(v, torch.Tensor):
            v = v.detach().cpu().numpy()
        if len(v.shape) == 3:
            v = v[0]
        if isinstance(f, torch.Tensor):
            f = f.detach().cpu().numpy()

        body = trimesh.Trimesh(vertices=v, faces=f)
        body.visual.face_colors = COLOR_SKIN  # –ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å
        scene_meshes.append(body)

    # –°–∫–µ–ª–µ—Ç
    if joints_np is not None:
        if len(joints_np.shape) == 3:
            joints_np = joints_np[0]
        skel = create_skeleton_mesh(joints_np)
        if skel:
            scene_meshes.append(skel)

    if scene_meshes:
        scene = trimesh.Scene(scene_meshes)
        # –ü–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º, —á—Ç–æ–±—ã —Å—Ç–æ—è–ª –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ (SMPL fix)
        rot = trimesh.transformations.rotation_matrix(np.radians(180), [1, 0, 0])
        scene.apply_transform(rot)

        scene.export(glb_out)
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {glb_out}")
        return os.path.abspath(glb_out), os.path.abspath(json_out)
    else:
        return None, None


# --- UI ---
with gr.Blocks(title="SAM 3D Body") as demo:
    gr.Markdown("# üßç SAM 3D Body Local")
    with gr.Row():
        inp = gr.Image(type="numpy", label="Input Image")
        with gr.Column():
            # clear_color —É–ø—Ä–∞–≤–ª—è–µ—Ç —Ñ–æ–Ω–æ–º –≤—å—é–≤–µ—Ä–∞ (—Å–≤–µ—Ç–ª–æ-—Å–µ—Ä—ã–π)
            out_3d = gr.Model3D(label="3D Result", clear_color=[0.9, 0.9, 0.9, 1.0])
            out_json = gr.File(label="Skeleton JSON")

    gr.Button("Generate 3D", variant="primary").click(
        run_inference, inp, [out_3d, out_json]
    )

if __name__ == "__main__":
    # share=True –¥–∞–µ—Ç –ø—É–±–ª–∏—á–Ω—É—é —Å—Å—ã–ª–∫—É
    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)
