import sys
import os
import argparse
import time
import torch
import cv2
import json
import numpy as np
import trimesh
from pathlib import Path
from tqdm import tqdm
from loguru import logger

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.getcwd())
from sam_3d_body import load_sam_3d_body, SAM3DBodyEstimator

# –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä
try:
    from tools.build_detector import HumanDetector

    HAS_DETECTOR = True
except ImportError:
    HAS_DETECTOR = False

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
CHECKPOINT_DIR = Path("checkpoints/sam-3d-body-dinov3")


def setup_logger(log_file=True):
    logger.remove()
    # –õ–æ–≥ –≤ –∫–æ–Ω—Å–æ–ª—å (–∫—Ä–∞—Ç–∫–∏–π)
    logger.add(
        sys.stderr,
        format="<green>{time:HH:mm:ss}</green> | <level>{message}</level>",
        level="INFO",
    )
    # –õ–æ–≥ –≤ —Ñ–∞–π–ª (–ø–æ–¥—Ä–æ–±–Ω—ã–π)
    if log_file:
        log_path = f"batch_log_{int(time.time())}.log"
        logger.add(log_path, rotation="10 MB", level="DEBUG")
        return log_path
    return None


def find_paths():
    if not CHECKPOINT_DIR.exists():
        logger.error(f"–ü–∞–ø–∫–∞ {CHECKPOINT_DIR} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        sys.exit(1)

    files = sorted(
        list(CHECKPOINT_DIR.glob("*.ckpt"))
        + list(CHECKPOINT_DIR.glob("*.pth"))
        + list(CHECKPOINT_DIR.glob("*.safetensors")),
        key=lambda x: x.stat().st_size,
        reverse=True,
    )
    if not files:
        logger.error("–ù–µ—Ç –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏!")
        sys.exit(1)

    mhr = CHECKPOINT_DIR / "assets" / "mhr_model.pt"
    if not mhr.exists():
        mhr = CHECKPOINT_DIR / "mhr_model.pt"

    return str(files[0]), str(mhr)


def serialize(obj):
    if isinstance(obj, torch.Tensor):
        return obj.detach().cpu().numpy().tolist()
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    return str(obj)


def get_gpu_memory():
    if torch.cuda.is_available():
        return f"{torch.cuda.memory_allocated() / 1024**3:.1f}GB"
    return "N/A"


def filter_images(input_dir, cams):
    """
    –°–∫–∞–Ω–∏—Ä—É–µ—Ç –ø–∞–ø–∫—É –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –ø–æ –∫–∞–º–µ—Ä–∞–º.
    –§–æ—Ä–º–∞—Ç: {cam_id}_*_{frame_id}.jpeg
    """
    valid_extensions = {".jpg", ".jpeg", ".png"}
    all_files = sorted(
        [p for p in input_dir.iterdir() if p.suffix.lower() in valid_extensions]
    )

    if not cams:
        return all_files

    filtered_files = []
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤–≤–æ–¥ –∫–∞–º–µ—Ä (—á—Ç–æ–±—ã '1' —Å—Ç–∞–ª–æ '01', –µ—Å–ª–∏ —Ñ–∞–π–ª—ã —Ç–∞–∫ –Ω–∞–∑—ã–≤–∞—é—Ç—Å—è, –∏–ª–∏ –∏—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)
    # –ù–æ –ª—É—á—à–µ –∏—Å–∫–∞—Ç—å –ø–æ –ø—Ä–µ—Ñ–∏–∫—Å—É –¥–æ –ø–µ—Ä–≤–æ–≥–æ '_'
    target_cams = set(cams)  # ['01', '02']

    for f in all_files:
        try:
            # –ü–∞—Ä—Å–∏–º –∏–º—è —Ñ–∞–π–ª–∞: 01_016BDOG#2_00000464.jpeg -> cam_id = "01"
            cam_id = f.name.split("_")[0]
            if cam_id in target_cams:
                filtered_files.append(f)
        except Exception:
            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã —Å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –Ω–µ–π–º–∏–Ω–≥–æ–º

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫—É (–µ—Å–ª–∏ —É–∫–∞–∑–∞–ª–∏ –∫–∞–º–µ—Ä—É, –∞ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç)
    if not filtered_files:
        logger.error(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –∫–∞–º–µ—Ä: {target_cams}")
        sys.exit(1)

    return filtered_files


def process_batch(args):
    input_path = Path(args.input)
    if not input_path.exists():
        logger.error(f"–í—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {input_path}")
        sys.exit(1)

    # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞–ø–æ–∫ –≤—ã–≤–æ–¥–∞
    if args.output_skeletons:
        skel_dir = Path(args.output_skeletons)
    else:
        skel_dir = input_path.parent / f"{input_path.name}_skeletons"

    if args.output_meshes:
        mesh_dir = Path(args.output_meshes)
    else:
        mesh_dir = input_path.parent / f"{input_path.name}_meshes"

    skel_dir.mkdir(parents=True, exist_ok=True)
    mesh_dir.mkdir(parents=True, exist_ok=True)

    log_file = setup_logger()
    logger.info(f"üìÇ –í—Ö–æ–¥: {input_path}")
    logger.info(f"üíÄ –°–∫–µ–ª–µ—Ç—ã: {skel_dir}")
    logger.info(f"üßä –ú–µ—à–∏: {mesh_dir}")
    if log_file:
        logger.info(f"üìù –õ–æ–≥: {log_file}")

    # 2. –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤
    files_to_process = filter_images(input_path, args.cams)
    logger.info(f"üì∏ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(files_to_process)}")

    # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    logger.info("‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
    try:
        ckpt, mhr = find_paths()
        model, cfg = load_sam_3d_body(ckpt, device=DEVICE, mhr_path=mhr)
        det = HumanDetector(name="vitdet", device=DEVICE) if HAS_DETECTOR else None
        estimator = SAM3DBodyEstimator(
            sam_3d_body_model=model, model_cfg=cfg, human_detector=det
        )
        logger.success("–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
        sys.exit(1)

    # 4. –ü—Ä–æ–≥—Ä–µ–≤ (Warmup) - —á—Ç–æ–±—ã tqdm –ø–æ–∫–∞–∑—ã–≤–∞–ª —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è —Å—Ä–∞–∑—É
    logger.info("üî• –ü—Ä–æ–≥—Ä–µ–≤ GPU...")
    try:
        dummy = np.zeros((512, 512, 3), dtype=np.uint8)
        cv2.imwrite("warmup_batch.jpg", dummy)
        with torch.inference_mode():
            estimator.process_one_image("warmup_batch.jpg", bbox_thr=0.5)
        os.remove("warmup_batch.jpg")
    except:
        pass

    # 5. –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
    pbar = tqdm(files_to_process, unit="img")
    success_count = 0
    skipped_count = 0
    error_count = 0

    for img_file in pbar:
        # –ò–º–µ–Ω–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        json_out = skel_dir / f"{img_file.stem}.json"
        glb_out = mesh_dir / f"{img_file.stem}.glb"

        # –ü—Ä–æ–ø—É—Å–∫ –≥–æ—Ç–æ–≤—ã—Ö
        if args.skip_existing:
            if json_out.exists() and glb_out.exists():
                skipped_count += 1
                pbar.set_description(f"Skip {img_file.name}")
                continue

        pbar.set_description(f"Proc {img_file.name}")

        try:
            # Inference
            with torch.inference_mode():
                outputs = estimator.process_one_image(str(img_file), bbox_thr=0.5)

            if not outputs:
                logger.warning(f"–ù–∞ —Ñ–æ—Ç–æ {img_file.name} –ª—é–¥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                # –ú–æ–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –ø—É—Å—Ç–æ–π JSON, —á—Ç–æ–±—ã –æ—Ç–º–µ—Ç–∏—Ç—å —Ñ–∞–∫—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
                with open(json_out, "w") as f:
                    json.dump([], f)
                continue

            # –°–æ–±–∏—Ä–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            all_people_data = []
            scene_meshes = []

            for i, person in enumerate(outputs):
                p_data = {"id": i}
                joints_np = None
                cam_t = np.array([0, 0, 0])

                # Joints extraction
                for key in ["pred_keypoints_3d", "pred_joints"]:
                    if key in person:
                        data = person[key]
                        if isinstance(data, torch.Tensor):
                            data = data.detach().cpu().numpy()
                        if len(data.shape) == 3:
                            data = data[0]
                        joints_np = data
                        p_data["joints_3d"] = serialize(joints_np)
                        break

                # Cam translation
                if "pred_cam_t" in person:
                    t = person["pred_cam_t"]
                    if isinstance(t, torch.Tensor):
                        t = t.detach().cpu().numpy()
                    if len(t.shape) == 2:
                        t = t[0]
                    cam_t = t

                # Mesh extraction
                v = person.get("pred_vertices")
                f = estimator.faces
                if v is not None:
                    if isinstance(v, torch.Tensor):
                        v = v.detach().cpu().numpy()
                    if len(v.shape) == 3:
                        v = v[0]
                    if isinstance(f, torch.Tensor):
                        f = f.detach().cpu().numpy()

                    # –°–¥–≤–∏–≥ –≤ –º–∏—Ä–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    v_world = v + cam_t
                    body = trimesh.Trimesh(vertices=v_world, faces=f)
                    # –¶–≤–µ—Ç –∫–æ–∂–∏ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –æ—Ç–∫—Ä—ã—Ç—å –≤ –ø—Ä–æ—Å–º–æ—Ç—Ä—â–∏–∫–µ)
                    body.visual.face_colors = [200, 200, 255, 255]
                    scene_meshes.append(body)

                all_people_data.append(p_data)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ JSON (–°–∫–µ–ª–µ—Ç—ã)
            with open(json_out, "w") as f:
                json.dump(all_people_data, f, indent=2)

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ GLB (–ú–µ—à–∏)
            if scene_meshes:
                scene = trimesh.Scene(scene_meshes)
                # –ü–æ–≤–æ—Ä–æ—Ç –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å GLB Y-up
                rot = trimesh.transformations.rotation_matrix(
                    np.radians(180), [1, 0, 0]
                )
                scene.apply_transform(rot)
                scene.export(glb_out)

            success_count += 1

            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ –±–∞—Ä–µ
            if success_count % 10 == 0:
                pbar.set_postfix({"VRAM": get_gpu_memory(), "Done": success_count})

        except Exception as e:
            error_count += 1
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {img_file.name}: {e}")
            continue

    logger.info("üèÅ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {success_count}")
    logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}")
    logger.info(f"‚ùå –û—à–∏–±–∫–∏: {error_count}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="–§–æ–Ω–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ SAM 3D Body")

    # –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç
    parser.add_argument("--input", type=str, required=True, help="–ü—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å —Ñ–æ—Ç–æ")

    # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏
    parser.add_argument("--output-skeletons", type=str, help="–ü–∞–ø–∫–∞ –¥–ª—è JSON —Å–∫–µ–ª–µ—Ç–æ–≤")
    parser.add_argument("--output-meshes", type=str, help="–ü–∞–ø–∫–∞ –¥–ª—è GLB –º–µ—à–µ–π")

    # –§–∏–ª—å—Ç—Ä—ã
    parser.add_argument(
        "--cams",
        nargs="+",
        type=str,
        help="–°–ø–∏—Å–æ–∫ –Ω–æ–º–µ—Ä–æ–≤ –∫–∞–º–µ—Ä (–Ω–∞–ø—Ä. '01' '02'). –ï—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ - –≤—Å–µ.",
    )
    parser.add_argument(
        "--skip-existing", action="store_true", help="–ü—Ä–æ–ø—É—Å–∫–∞—Ç—å —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"
    )

    args = parser.parse_args()

    process_batch(args)
